{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Recommendation System - Hybrid Ensemble Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/event-recsys-mvp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from models.content_based import ContentBasedRecommender\n",
    "from models.collaborative import CollaborativeFilteringRecommender\n",
    "from models.social import SocialRecommender\n",
    "from utils.metrics import evaluate_recommendations\n",
    "from utils.temporal_split import temporal_split_per_user, print_split_stats\n",
    "from utils.preprocessing import InteractionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train data: 15398 interactions\n",
      "Events: 3137972\n",
      "Event attendees: 24144\n",
      "User friends: 38202\n"
     ]
    }
   ],
   "source": [
    "raw_dir = Path(\"../data/raw\")\n",
    "\n",
    "train_raw = pd.read_csv(raw_dir / \"train.csv\")\n",
    "events_raw = pd.read_csv(raw_dir / \"events.csv\")\n",
    "event_attendees = pd.read_csv(raw_dir / \"event_attendees.csv\")\n",
    "user_friends = pd.read_csv(raw_dir / \"user_friends.csv\")\n",
    "\n",
    "print(f\"Raw train data: {len(train_raw)} interactions\")\n",
    "print(f\"Events: {len(events_raw)}\")\n",
    "print(f\"Event attendees: {len(event_attendees)}\")\n",
    "print(f\"User friends: {len(user_friends)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEMPORAL SPLIT STATISTICS\n",
      "============================================================\n",
      "\n",
      "TRAIN SET:\n",
      "  Total interactions: 7393\n",
      "  Unique users: 2034\n",
      "  Unique events: 4733\n",
      "  Interested=1: 1337\n",
      "\n",
      "VALIDATION SET:\n",
      "  Total interactions: 8005\n",
      "  Unique users: 2034\n",
      "  Unique events: 5127\n",
      "  Interested=1: 2794\n",
      "\n",
      "OVERLAP:\n",
      "  Users in both: 2034\n",
      "  Events in both: 1014\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = temporal_split_per_user(train_raw, train_ratio=0.5, min_interactions=3)\n",
    "\n",
    "print_split_stats(train_df, val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached processed events...\n",
      "Processed events shape: (3137972, 113)\n",
      "Event categories: 30\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import EventFeatureExtractor\n",
    "\n",
    "processed_events_path = Path(\"../data/processed/events_processed.csv\")\n",
    "\n",
    "if processed_events_path.exists():\n",
    "    print(\"Loading cached processed events...\")\n",
    "    events = pd.read_csv(processed_events_path)\n",
    "else:\n",
    "    print(\"Processing events (this will take a few minutes)...\")\n",
    "    extractor = EventFeatureExtractor(n_clusters=30)\n",
    "    events = extractor.fit_transform(events_raw)\n",
    "    events.to_csv(processed_events_path, index=False)\n",
    "    print(\"Events processed and cached!\")\n",
    "\n",
    "print(f\"Processed events shape: {events.shape}\")\n",
    "print(f\"Event categories: {events['event_category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Interaction Matrices (for Collaborative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building interaction matrices...\n",
      "R matrix shape: (2034, 4733)\n",
      "W matrix shape: (2034, 4733)\n"
     ]
    }
   ],
   "source": [
    "MATRIX_PARAMS = {\n",
    "    \"weight_purchase\": 3.0,\n",
    "    \"weight_interested\": 1.0,\n",
    "    \"weight_not_interested\": 0.5,\n",
    "    \"weight_unseen\": 0.1\n",
    "}\n",
    "\n",
    "print(\"Building interaction matrices...\")\n",
    "matrix_builder = InteractionMatrix(**MATRIX_PARAMS)\n",
    "R, W, user_to_idx, event_to_idx = matrix_builder.build_matrices(train_df, event_attendees)\n",
    "\n",
    "print(f\"R matrix shape: {R.shape}\")\n",
    "print(f\"W matrix shape: {W.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best Hyperparameters from Individual Models\n",
    "\n",
    "Based on previous experiments, we use the best hyperparameters found for each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_PARAMS = {\n",
    "    \"weight_purchase\": 3.0,\n",
    "    \"weight_interested\": 1.0,\n",
    "    \"temporal_decay\": 0.01,\n",
    "    \"geo_top_k\": 1000\n",
    "}\n",
    "\n",
    "COLLABORATIVE_PARAMS = {\n",
    "    \"n_factors\": 10,\n",
    "    \"regularization\": 0.01,\n",
    "    \"iterations\": 15,\n",
    "    \"random_state\": 42,\n",
    "    \"geo_top_k\": 3000\n",
    "}\n",
    "\n",
    "SOCIAL_PARAMS = {\n",
    "    \"weight_attending\": 2.0,\n",
    "    \"weight_interested\": 1.0\n",
    "}\n",
    "\n",
    "K = 200\n",
    "N_TEST_USERS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Content-Based model...\n",
      "✓ Content-Based trained\n",
      "\n",
      "Training Collaborative Filtering model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/event-recsys-mvp/lib/python3.8/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 10 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 15/15 [00:00<00:00, 572.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Collaborative trained\n",
      "\n",
      "Training Social model...\n",
      "✓ Social trained\n",
      "\n",
      "==================================================\n",
      "All models trained successfully!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Content-Based model...\")\n",
    "cb_model = ContentBasedRecommender(**CONTENT_PARAMS)\n",
    "cb_model.fit(events, train_df, event_attendees)\n",
    "print(\"✓ Content-Based trained\")\n",
    "\n",
    "print(\"\\nTraining Collaborative Filtering model...\")\n",
    "cf_model = CollaborativeFilteringRecommender(**COLLABORATIVE_PARAMS)\n",
    "cf_model.fit(R, W, user_to_idx, event_to_idx, train_df, events)\n",
    "print(\"✓ Collaborative trained\")\n",
    "\n",
    "print(\"\\nTraining Social model...\")\n",
    "social_model = SocialRecommender(**SOCIAL_PARAMS)\n",
    "social_model.fit(user_friends, train_df, event_attendees)\n",
    "print(\"✓ Social trained\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All models trained successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with labels in validation: 1501\n",
      "Evaluating on 100 users...\n"
     ]
    }
   ],
   "source": [
    "val_with_labels = val_df[(val_df[\"interested\"] == 1) | (val_df[\"not_interested\"] == 1)]\n",
    "users_with_labels = val_with_labels[\"user\"].unique()\n",
    "\n",
    "print(f\"Users with labels in validation: {len(users_with_labels)}\")\n",
    "\n",
    "if N_TEST_USERS:\n",
    "    test_users = users_with_labels[:N_TEST_USERS]\n",
    "else:\n",
    "    test_users = users_with_labels\n",
    "\n",
    "print(f\"Evaluating on {len(test_users)} users...\")\n",
    "\n",
    "actuals = {}\n",
    "not_interested = {}\n",
    "\n",
    "for user in test_users:\n",
    "    actuals[user] = val_df[(val_df[\"user\"] == user) & (val_df[\"interested\"] == 1)][\"event\"].tolist()\n",
    "    not_interested[user] = val_df[(val_df[\"user\"] == user) & (val_df[\"not_interested\"] == 1)][\"event\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Get Scores from Individual Models\n",
    "\n",
    "Get raw scores (not just top-K) from each model for the test users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting scores from individual models...\n",
      "✓ Scores collected from all models\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting scores from individual models...\")\n",
    "\n",
    "cb_scores = {}\n",
    "cf_scores = {}\n",
    "social_scores = {}\n",
    "\n",
    "for user in test_users:\n",
    "    cb_recs = cb_model.recommend(user, n=K, exclude_seen=True)\n",
    "    cf_recs = cf_model.recommend(user, n=K, exclude_seen=True)\n",
    "    social_recs = social_model.recommend(user, n=K, exclude_seen=True)\n",
    "    \n",
    "    cb_scores[user] = {event: K - i for i, event in enumerate(cb_recs)}\n",
    "    cf_scores[user] = {event: K - i for i, event in enumerate(cf_recs)}\n",
    "    social_scores[user] = {event: K - i for i, event in enumerate(social_recs)}\n",
    "\n",
    "print(\"✓ Scores collected from all models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hybrid Ensemble with Min-Max Normalization\n",
    "\n",
    "Combine scores from all three models using weighted ensemble with min-max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing scores...\n",
      "✓ Scores normalized\n"
     ]
    }
   ],
   "source": [
    "def normalize_scores(scores_dict):\n",
    "    \"\"\"Min-max normalization: scales scores to [0, 1]\"\"\"\n",
    "    normalized = {}\n",
    "    \n",
    "    for user, event_scores in scores_dict.items():\n",
    "        if not event_scores:\n",
    "            normalized[user] = {}\n",
    "            continue\n",
    "        \n",
    "        scores = np.array(list(event_scores.values()))\n",
    "        min_score = scores.min()\n",
    "        max_score = scores.max()\n",
    "        \n",
    "        if max_score == min_score:\n",
    "            normalized[user] = {event: 1.0 for event in event_scores}\n",
    "        else:\n",
    "            normalized[user] = {\n",
    "                event: (score - min_score) / (max_score - min_score)\n",
    "                for event, score in event_scores.items()\n",
    "            }\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "print(\"Normalizing scores...\")\n",
    "cb_scores_norm = normalize_scores(cb_scores)\n",
    "cf_scores_norm = normalize_scores(cf_scores)\n",
    "social_scores_norm = normalize_scores(social_scores)\n",
    "print(\"✓ Scores normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid recommendation function ready\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommend(user, w_cb, w_cf, w_social, n=200):\n",
    "    \"\"\"Combine normalized scores with weights\"\"\"\n",
    "    combined_scores = defaultdict(float)\n",
    "    \n",
    "    for event, score in cb_scores_norm[user].items():\n",
    "        combined_scores[event] += w_cb * score\n",
    "    \n",
    "    for event, score in cf_scores_norm[user].items():\n",
    "        combined_scores[event] += w_cf * score\n",
    "    \n",
    "    for event, score in social_scores_norm[user].items():\n",
    "        combined_scores[event] += w_social * score\n",
    "    \n",
    "    sorted_events = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [event for event, _ in sorted_events[:n]]\n",
    "\n",
    "print(\"Hybrid recommendation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate with Equal Weights (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hybrid with equal weights (1/3, 1/3, 1/3)...\n",
      "\n",
      "==================================================\n",
      "HYBRID (EQUAL WEIGHTS) RESULTS @ K=200\n",
      "==================================================\n",
      "Recall@K            : 0.46626\n",
      "Hit_Rate@K          : 0.61000\n",
      "Contamination@K     : 0.00010\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing hybrid with equal weights (1/3, 1/3, 1/3)...\")\n",
    "\n",
    "hybrid_predictions = {}\n",
    "for user in test_users:\n",
    "    hybrid_predictions[user] = hybrid_recommend(user, w_cb=1/3, w_cf=1/3, w_social=1/3, n=K)\n",
    "\n",
    "metrics = evaluate_recommendations(actuals, hybrid_predictions, not_interested, k=K)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"HYBRID (EQUAL WEIGHTS) RESULTS @ K={K}\")\n",
    "print(f\"{'='*50}\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:20s}: {value:.5f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter Tuning: Weight Combinations\n",
    "\n",
    "Test different weight combinations to find the optimal ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Equal: CB=0.33, CF=0.33, Social=0.33 (1/10)\n",
      "============================================================\n",
      "Recall@200: 0.46626\n",
      "Hit_Rate@200: 0.61000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing CB Heavy: CB=0.50, CF=0.25, Social=0.25 (2/10)\n",
      "============================================================\n",
      "Recall@200: 0.45007\n",
      "Hit_Rate@200: 0.59000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing CF Heavy: CB=0.25, CF=0.50, Social=0.25 (3/10)\n",
      "============================================================\n",
      "Recall@200: 0.45983\n",
      "Hit_Rate@200: 0.60000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing Social Heavy: CB=0.25, CF=0.25, Social=0.50 (4/10)\n",
      "============================================================\n",
      "Recall@200: 0.49567\n",
      "Hit_Rate@200: 0.63000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing CB Focus: CB=0.40, CF=0.30, Social=0.30 (5/10)\n",
      "============================================================\n",
      "Recall@200: 0.45483\n",
      "Hit_Rate@200: 0.59000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing CF Focus: CB=0.30, CF=0.40, Social=0.30 (6/10)\n",
      "============================================================\n",
      "Recall@200: 0.46626\n",
      "Hit_Rate@200: 0.61000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing Social Focus: CB=0.30, CF=0.30, Social=0.40 (7/10)\n",
      "============================================================\n",
      "Recall@200: 0.46733\n",
      "Hit_Rate@200: 0.61000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing Social Strong: CB=0.20, CF=0.30, Social=0.50 (8/10)\n",
      "============================================================\n",
      "Recall@200: 0.50710\n",
      "Hit_Rate@200: 0.64000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing CF+Social: CB=0.10, CF=0.40, Social=0.50 (9/10)\n",
      "============================================================\n",
      "Recall@200: 0.52995\n",
      "Hit_Rate@200: 0.65000\n",
      "Time: 0.0s\n",
      "\n",
      "============================================================\n",
      "Testing CB Dominant: CB=0.60, CF=0.20, Social=0.20 (10/10)\n",
      "============================================================\n",
      "Recall@200: 0.43007\n",
      "Hit_Rate@200: 0.58000\n",
      "Time: 0.0s\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS - Weight Combinations\n",
      "================================================================================\n",
      "Configuration            CB     CF Social     Recall   Hit_Rate\n",
      "----------------------------------------------------------------------\n",
      "Equal                  0.33   0.33   0.33    0.46626    0.61000\n",
      "CB Heavy               0.50   0.25   0.25    0.45007    0.59000\n",
      "CF Heavy               0.25   0.50   0.25    0.45983    0.60000\n",
      "Social Heavy           0.25   0.25   0.50    0.49567    0.63000\n",
      "CB Focus               0.40   0.30   0.30    0.45483    0.59000\n",
      "CF Focus               0.30   0.40   0.30    0.46626    0.61000\n",
      "Social Focus           0.30   0.30   0.40    0.46733    0.61000\n",
      "Social Strong          0.20   0.30   0.50    0.50710    0.64000\n",
      "CF+Social              0.10   0.40   0.50    0.52995    0.65000\n",
      "CB Dominant            0.60   0.20   0.20    0.43007    0.58000\n",
      "\n",
      "================================================================================\n",
      "BEST CONFIGURATION: CF+Social\n",
      "Weights: CB=0.10, CF=0.40, Social=0.50\n",
      "Recall@200: 0.52995\n",
      "Hit_Rate@200: 0.65000\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "weight_combinations = [\n",
    "    (1/3, 1/3, 1/3, \"Equal\"),\n",
    "    (0.5, 0.25, 0.25, \"CB Heavy\"),\n",
    "    (0.25, 0.5, 0.25, \"CF Heavy\"),\n",
    "    (0.25, 0.25, 0.5, \"Social Heavy\"),\n",
    "    (0.4, 0.3, 0.3, \"CB Focus\"),\n",
    "    (0.3, 0.4, 0.3, \"CF Focus\"),\n",
    "    (0.3, 0.3, 0.4, \"Social Focus\"),\n",
    "    (0.2, 0.3, 0.5, \"Social Strong\"),\n",
    "    (0.1, 0.4, 0.5, \"CF+Social\"),\n",
    "    (0.6, 0.2, 0.2, \"CB Dominant\"),\n",
    "]\n",
    "\n",
    "results_weights = []\n",
    "\n",
    "for idx, (w_cb, w_cf, w_social, label) in enumerate(weight_combinations, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {label}: CB={w_cb:.2f}, CF={w_cf:.2f}, Social={w_social:.2f} ({idx}/{len(weight_combinations)})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    predictions = {}\n",
    "    for user in test_users:\n",
    "        predictions[user] = hybrid_recommend(user, w_cb=w_cb, w_cf=w_cf, w_social=w_social, n=K)\n",
    "    \n",
    "    metrics = evaluate_recommendations(actuals, predictions, not_interested, k=K)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    results_weights.append({\n",
    "        \"label\": label,\n",
    "        \"w_cb\": w_cb,\n",
    "        \"w_cf\": w_cf,\n",
    "        \"w_social\": w_social,\n",
    "        \"recall\": metrics[\"Recall@K\"],\n",
    "        \"hit_rate\": metrics[\"Hit_Rate@K\"],\n",
    "        \"contamination\": metrics[\"Contamination@K\"]\n",
    "    })\n",
    "    \n",
    "    print(f\"Recall@{K}: {metrics['Recall@K']:.5f}\")\n",
    "    print(f\"Hit_Rate@{K}: {metrics['Hit_Rate@K']:.5f}\")\n",
    "    print(f\"Time: {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF RESULTS - Weight Combinations\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"{'Configuration':<20} {'CB':>6} {'CF':>6} {'Social':>6} {'Recall':>10} {'Hit_Rate':>10}\")\n",
    "print(f\"{'-'*70}\")\n",
    "for r in results_weights:\n",
    "    print(f\"{r['label']:<20} {r['w_cb']:>6.2f} {r['w_cf']:>6.2f} {r['w_social']:>6.2f} {r['recall']:>10.5f} {r['hit_rate']:>10.5f}\")\n",
    "\n",
    "best = max(results_weights, key=lambda x: x['recall'])\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST CONFIGURATION: {best['label']}\")\n",
    "print(f\"Weights: CB={best['w_cb']:.2f}, CF={best['w_cf']:.2f}, Social={best['w_social']:.2f}\")\n",
    "print(f\"Recall@{K}: {best['recall']:.5f}\")\n",
    "print(f\"Hit_Rate@{K}: {best['hit_rate']:.5f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event-recsys-mvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
